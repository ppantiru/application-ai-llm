<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>AppA - Chat Interface</title>
</head>
<body>
  <h2>Placeholder for web page</h2>

  <script src="aillm.js"></script>
  <script src="chatUILoader.js"></script>
  <ion-app>      
    <ion-header>
      <ion-toolbar color="primary">
        <ion-title>Home</ion-title>
      </ion-toolbar>
    </ion-header>
    <ion-content>
      <ion-list>
        <ion-item style="height: 3000px">
            I'm here for scroll!
        </ion-item>
      </ion-list>
    </ion-content>
  </ion-app>
</body>

</html>

<!-- // Usage example
XWikiAiAPI.setApiKey("sk-xxx");

// Since getModels and getPrompts are asynchronous, you need to handle them properly
XWikiAiAPI.getModels().then(models => console.log(models)).catch(err => console.error(err));
XWikiAiAPI.getPrompts().then(prompts => console.log(prompts)).catch(err => console.error(err));

let completionRequest = new ChatCompletionRequest(
    "AI.Models.GPT3\\.5-turbo", // model
    0.5, // temperature
    [{role: "user", content: "What's the capital of Zimbabwe?"}], // messages
    true,
);

// Add another message if needed
// completionRequest.addMessage("assistant", "The capital of Zimbabwe is Harare.");
// completionRequest.addMessage("user", "Tell me more about it.");

XWikiAiAPI.getCompletions(completionRequest, (messageChunk) => {
    console.log("New message chunk:", messageChunk);
});
 -->
